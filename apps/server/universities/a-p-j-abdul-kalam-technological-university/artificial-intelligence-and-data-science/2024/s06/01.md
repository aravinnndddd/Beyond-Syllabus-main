---
country: "india"
university: "ktu"
branch: "ad"
version: "2024"
semester: "6"
course_code: "pcadt601"
course_title: "deep-learning"
language: "english"
contributor: "@indhu-subash"
---

# PCADT601: Deep Learning  

## Course Objectives

1. To get an insight into various design parameters of a deep learning  
2. To introduce deep learning architectures for various domains such as text, multimedia and GenAI

---

## Syllabus Modules

### Module 1: Introduction to Deep learning
- Introduction, Deep feed forward network  
- Activation functions – Sign, Sigmoid, Tanh, ReLU, leaky ReLU, Hard Tanh, Softmax  
- Loss function  
- Training a Neural Network with Backpropagation  
- Practical issues in neural network training  
- Overfitting, Underfitting, Hyper parameters and Validation sets, Estimators -Bias and Variance  

### Module 2: Network Design parameters
- Introduction, setup and initialization Kaiming, Xavier weight initialization  
- Vanishing and exploding gradient problems  
- Optimization techniques - Gradient Descent (GD), Stochastic GD, GD with momentum, GD with Nesterov momentum  
- Parameter specific learning rates: AdaGrad, RMSProp, Adam  
- Regularization Techniques - L1 and L2 regularization, Early stopping  
- Dataset augmentation, Parameter tying and sharing, Ensemble methods, Dropout, Batch normalization  

### Module 3: Convolutional Neural Network
- Basic structure of a CNN  
- Basic layers and operations in CNN: Convolution operation, effect of stride and padding, Fully Connected layers, CNN layers  
- Building a CNN model: Training a CNN  
- Estimation of Tensor size number of features in CNN layers  
- Transfer learning (size similarity matrix)  
- Pre-trained architectures- AlexNet, ResNet-50, GoogleNet  

### Module 4: Deep learning models for text processing
- Recurrent Neural Network architecture  
- Variants of RNN architectures: Deep Recurrent Neural Network, Recursive Neural Network, Bidirectional recurrent neural network, Encoder-Decoder architecture, LSTM, GRU  
- Auto Encoders and Generative models
- Variational AutoEncoder-under complete Auto-encoder, stochastic encoder, denoising encoder  
- Applications of Autoencoders  
- Generative models - Boltzmann machines, Deep Belief Networks, Generative Adversarial Networks  

---

## Reference Books

1. Deep Learning – Goodfellow, I., Bengio,Y., and Courville, A., MIT Press, 1/e, 2016  
2. Neural Networks and Deep Learning – Aggarwal, Charu C, Springer International, 1/e, 2018  
3. Deep Learning, Core Concepts, Methods and Applications – M Gopal, Pearson Education, 1/e, 2022  
4. Fundamentals of Deep Learning: Designing Next-Generation Machine Intelligence Algorithm – Nikhil Buduma and Nicholas Locascio, O'Reilly Media, 1/e, 2017  

---
