---
country: "india"
university: "ktu"
branch: "electronics-and-communication-engineering"
version: "2019"
semester: 8
course_code: "ect444"
course_title: "pattern-recognition"
language: "english"
contributor: "@alwynrejicser"
---

# ECT444: Pattern Recognition

## Course Objectives

- Understand the fundamentals and various approaches to pattern recognition.
- Explore statistical pattern classification techniques.
- Apply estimation methods to determine model parameters.
- Study neural networks and their role in pattern recognition.
- Learn the foundations of deep learning and convolutional neural networks.

## Course Outcomes

- Understand the basics of statistical pattern recognition.
- Apply statistical methods in linear classification.
- Apply linear algebra and statistical methods in parameter and non-parameter estimation.
- Apply statistical methods in non-linear classification and neural networks.
- Understand the basics of deep learning networks, especially convolutional neural networks.

## Course Content

### Module I: Introduction to Pattern Recognition

- Basics of Pattern Recognition System
- Various Applications and Classification of Pattern Recognition Systems
- Design of Pattern Recognition System
- Statistical Pattern Recognition:
  - Review of Probability Theory
  - Gaussian Distribution
  - Bayes Decision Theory
  - Optimal Solutions for:
    - Minimum Error Criteria
    - Minimum Risk Criteria

### Module II: Linear Classification

- Linear Classifiers
- Linearly Separable Classes
- Normal Density
- Discriminant Functions
- Decision Surfaces
- Linear Discriminants:
  - Binary Class
  - Multiple Classes
- Cost Functions
- Perceptron Algorithm
- Support Vector Machine (SVM)
- Fisherâ€™s Linear Discriminant

### Module III: Parameter and Non-Parameter Estimation

- **Parameter Estimation Methods**:
  - Maximum-Likelihood Estimation
  - Bayesian Parameter Estimation
  - Mixture Models
  - Mixtures of Gaussians
  - Expectation-Maximization (EM) Method
- **Non-Parameter Methods**:
  - Parzen Window Method
  - K-Nearest Neighbour Density Estimation
  - Nearest Neighbour Rule

### Module IV: Nonlinear Classification and Neural Networks

- Nonlinear Classifiers
- XOR Problem
- Multilayer Perceptrons:
  - Two-Layer and General MLPs
  - Neural Networks Architecture
  - Feedforward Networks
  - Hidden Units and Activation Function
  - Weight Vector and Bias
  - Cost Functions
  - Forward and Backward Propagation
  - Learning via Gradient Descent
  - Backpropagation Algorithm

### Module V: Deep Learning and Convolutional Neural Networks

- Introduction to Deep Learning Networks
- Deep Feedforward Networks
- ReLU Activation Function
- Bias-Variance Tradeoff
- Regularization and Dropout
- Vanishing/Exploding Gradients
- Weight Initialization for Deep Networks
- Basics of Convolutional Neural Networks (CNNs)
- Layers of CNNs

## References

1. Hastie, T., Tibshirani, R. & Friedman, J., *The Elements of Statistical Learning*, Springer, 2001.
2. Theodoridis, S. & Koutroumbas, K., *Pattern Recognition*, Academic Press, 2003.
3. Ian Goodfellow, Yoshua Bengio, Aaron Courville, *Deep Learning*, MIT Press, 2016.
4. Morton Nadier & Eric P. Smith, *Pattern Recognition Engineering*, John Wiley & Sons, 1993.
5. Bishop, C. M., *Pattern Recognition and Machine Learning*, Springer, 2006.
6. Duda, R.O., Hart, P.E. & Stork, D.G., *Pattern Classification*, Wiley, 2001.

