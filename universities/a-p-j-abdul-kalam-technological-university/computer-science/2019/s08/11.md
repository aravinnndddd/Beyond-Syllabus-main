---
country: "india"
university: "ktu"
branch: "computer-science-and-engineering"
version: "2019"
semester: 8
course_code: "cst436"
course_title: "parallel-computing"
language: "english"
contributor: "@UmarAlMukhtar"
---

# CST436: Parallel Computing  

## Course Objectives  
* Summarize the key parallel computational models.  
* Apply parallel and distributed algorithms in problem solving.  
* Understand communication models for parallel algorithm development.  
* Develop parallel algorithms using the message passing paradigm.  
* Formulate parallel algorithms for shared memory architectures.  
* Demonstrate basic skills of heterogeneous computing with GPUs.  

## Modules  

### Module 1 – Principles of Parallel Algorithm Design  
* Introduction to Parallel Processing platforms.  
* Preliminaries, decomposition techniques.  
* Characteristics of tasks and interactions.  
* Mapping techniques for load balancing.  
* Methods for containing interaction overheads.  
* Parallel algorithm models.  

### Module 2 – Communication Operations  
* Basic communication operations – One-to-All broadcast, All-to-One reduction, All-to-All broadcast and reduction.  
* All-reduce and prefix-sum operations.  
* Scatter and gather, All-to-All personalized communication, circular shift.  
* Techniques to improve the speed of communication operations.  

### Module 3 – Programming Using the Message Passing Paradigm  
* Principles of message-passing programming.  
* Building blocks: Send and Receive operations.  
* MPI (Message Passing Interface).  
* Overlapping communication with computation.  
* Collective communication and computation operations.  
* Groups and communicators.  

### Module 4 – Programming Shared Address Space Platforms  
* Thread basics – Need for threads, POSIX Thread API.  
* Synchronization primitives in POSIX.  
* Controlling thread and synchronization attributes, thread cancellation.  
* Composite synchronization constructs.  
* OpenMP – Standard for directive-based parallel programming.  
* Specifying concurrent tasks, synchronization constructs, data handling in OpenMP.  
* OpenMP library functions.  
* Application – Parallel algorithm development for matrix multiplication.  

### Module 5 – GPU Programming  
* Heterogeneous parallel computing and GPU architecture.  
* Data parallel computing, CUDA C program structure.  
* Kernel functions and threading, device memory and data transfer.  
* Thread organization, synchronization, resource assignment.  
* Querying device properties, scheduling and latency tolerance.  
* Memory access efficiency, CUDA memory types.  
* Tiled matrix multiplication kernel and optimization techniques.  

## References  
* Ananth Grama, Anshul Gupta, George Karypis, Vipin Kumar – *Introduction to Parallel Computing*, 2nd Ed, Addison-Wesley, 2003.  
* David B. Kirk, Wen-mei W. Hwu – *Programming Massively Parallel Processors: A Hands-on Approach*, 3rd Ed., Morgan Kaufman, 2016.  
* Steven Brawer – *Introduction to Parallel Computing*, Academic Press, 1989.  
* Barbara Chapman, Gabriele Jost, Ruud van der Pas – *Using OpenMP: Portable Shared Memory Parallel Programming*, MIT Press, 2008.  
* William Gropp, Ewing Lusk, Anthony Skjellum – *Using MPI: Portable Parallel Programming with the Message-Passing Interface*, 3rd Ed, MIT Press, 2014.  
* Thomas Rauber, Gudula Rünger – *Parallel Programming for Multicore and Cluster Systems*, Springer, 2010.  
